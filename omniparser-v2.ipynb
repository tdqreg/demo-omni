{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "IS_KAGGLE = False\n",
    "\n",
    "working_dir = \".\"\n",
    "if IS_KAGGLE:\n",
    "    working_dir = \"/kaggle/working\"\n",
    "\n",
    "!git clone https://github.com/tdqreg/demo-omni.git\n",
    "import os\n",
    "os.chdir(f\"{working_dir}/demo-omni\")\n",
    "\n",
    "%pip install -r requirements.txt\n",
    "\n",
    "!for f in icon_detect/{train_args.yaml,model.pt,model.yaml} icon_caption/{config.json,generation_config.json,model.safetensors}; do hf download microsoft/OmniParser-v2.0 \"$f\" --local-dir weights; done\n",
    "!mv weights/icon_caption weights/icon_caption_florence\n",
    "\n",
    "# Nếu dùng transformers mới quá sẽ ko bị bỏ đi spda hoặc flashattention nên cần downgrade lại\n",
    "%pip install transformers==4.49.0 \n",
    "\n",
    "import base64\n",
    "from util.utils import check_ocr_box, get_yolo_model, get_caption_model_processor, get_som_labeled_img\n",
    "\n",
    "yolo_model = get_yolo_model(model_path='weights/icon_detect/model.pt')\n",
    "caption_model_processor = get_caption_model_processor(model_name=\"florence2\", model_name_or_path=\"weights/icon_caption_florence\")\n",
    "\n",
    "# Test thử ảnh ban đầu\n",
    "from PIL import Image\n",
    "image_input = Image.open(f\"./imgs/mspaint.png\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(image_input)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 13\u001b[0m\n\u001b[1;32m      5\u001b[0m box_overlay_ratio \u001b[38;5;241m=\u001b[39m image_input\u001b[38;5;241m.\u001b[39msize[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m3200\u001b[39m\n\u001b[1;32m      6\u001b[0m draw_bbox_config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext_scale\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.8\u001b[39m \u001b[38;5;241m*\u001b[39m box_overlay_ratio,\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext_thickness\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m box_overlay_ratio), \u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext_padding\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m3\u001b[39m \u001b[38;5;241m*\u001b[39m box_overlay_ratio), \u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthickness\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m3\u001b[39m \u001b[38;5;241m*\u001b[39m box_overlay_ratio), \u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     11\u001b[0m }\n\u001b[0;32m---> 13\u001b[0m ocr_bbox_rslt, is_goal_filtered \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_ocr_box\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisplay_img\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_bb_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mxyxy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgoal_filtering\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43measyocr_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mparagraph\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext_threshold\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_paddleocr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_paddleocr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m text, ocr_bbox \u001b[38;5;241m=\u001b[39m ocr_bbox_rslt\n\u001b[1;32m     15\u001b[0m dino_labled_img, label_coordinates, parsed_content_list \u001b[38;5;241m=\u001b[39m get_som_labeled_img(image_input, yolo_model, BOX_TRESHOLD \u001b[38;5;241m=\u001b[39m box_threshold, output_coord_in_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, ocr_bbox\u001b[38;5;241m=\u001b[39mocr_bbox,draw_bbox_config\u001b[38;5;241m=\u001b[39mdraw_bbox_config, caption_model_processor\u001b[38;5;241m=\u001b[39mcaption_model_processor, ocr_text\u001b[38;5;241m=\u001b[39mtext,iou_threshold\u001b[38;5;241m=\u001b[39miou_threshold, imgsz\u001b[38;5;241m=\u001b[39mimgsz,)  \n",
      "File \u001b[0;32m~/demo-omni/util/utils.py:517\u001b[0m, in \u001b[0;36mcheck_ocr_box\u001b[0;34m(image_source, display_img, output_bb_format, goal_filtering, easyocr_args, use_paddleocr)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[38;5;66;03m# result = paddle_ocr.ocr(image_np, cls=False)[0]\u001b[39;00m\n\u001b[1;32m    516\u001b[0m     result \u001b[38;5;241m=\u001b[39m paddle_ocr\u001b[38;5;241m.\u001b[39mocr(image_np)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 517\u001b[0m     coord \u001b[38;5;241m=\u001b[39m [item[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m result \u001b[38;5;28;01mif\u001b[39;00m item[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m text_threshold]\n\u001b[1;32m    518\u001b[0m     text \u001b[38;5;241m=\u001b[39m [item[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m result \u001b[38;5;28;01mif\u001b[39;00m item[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m text_threshold]\n\u001b[1;32m    519\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# EasyOCR\u001b[39;00m\n",
      "File \u001b[0;32m~/demo-omni/util/utils.py:517\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[38;5;66;03m# result = paddle_ocr.ocr(image_np, cls=False)[0]\u001b[39;00m\n\u001b[1;32m    516\u001b[0m     result \u001b[38;5;241m=\u001b[39m paddle_ocr\u001b[38;5;241m.\u001b[39mocr(image_np)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 517\u001b[0m     coord \u001b[38;5;241m=\u001b[39m [item[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m result \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mitem\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m>\u001b[39m text_threshold]\n\u001b[1;32m    518\u001b[0m     text \u001b[38;5;241m=\u001b[39m [item[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m result \u001b[38;5;28;01mif\u001b[39;00m item[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m text_threshold]\n\u001b[1;32m    519\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# EasyOCR\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "box_threshold = 0.05\n",
    "iou_threshold = 0.1\n",
    "use_paddleocr = True\n",
    "imgsz_component = 640\n",
    "box_overlay_ratio = image_input.size[0] / 3200\n",
    "draw_bbox_config = {\n",
    "    'text_scale': 0.8 * box_overlay_ratio,\n",
    "    'text_thickness': max(int(2 * box_overlay_ratio), 1),\n",
    "    'text_padding': max(int(3 * box_overlay_ratio), 1),\n",
    "    'thickness': max(int(3 * box_overlay_ratio), 1),\n",
    "}\n",
    "\n",
    "ocr_bbox_rslt, is_goal_filtered = check_ocr_box(image_input, display_img = False, output_bb_format='xyxy', goal_filtering=None, easyocr_args={'paragraph': False, 'text_threshold':0.9}, use_paddleocr=use_paddleocr)\n",
    "text, ocr_bbox = ocr_bbox_rslt\n",
    "dino_labled_img, label_coordinates, parsed_content_list = get_som_labeled_img(image_input, yolo_model, BOX_TRESHOLD = box_threshold, output_coord_in_ratio=True, ocr_bbox=ocr_bbox,draw_bbox_config=draw_bbox_config, caption_model_processor=caption_model_processor, ocr_text=text,iou_threshold=iou_threshold, imgsz=imgsz,)  \n",
    "result_img = Image.open(io.BytesIO(base64.b64decode(dino_labled_img)))\n",
    "print('finish processing')\n",
    "parsed_content_list = '\\n'.join([f'icon {i}: ' + str(v) for i,v in enumerate(parsed_content_list)])\n",
    "\n",
    "plt.imshow(result_img)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8219052,
     "sourceId": 12985385,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
